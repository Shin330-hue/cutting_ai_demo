# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# pip install sentence-transformers scikit-learn streamlit pandas google-generativeai python-dotenv

import streamlit as st
# é‡è¦: set_page_configã¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆç›´å¾Œã«å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹
st.set_page_config(page_title="åˆ‡å‰ŠåŠ å·¥ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼", layout="wide")

import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import google.generativeai as genai
import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_model():
    return SentenceTransformer('sonoisa/sentence-bert-base-ja-mean-tokens')

@st.cache_data
def load_knowledge():
    try:
        df = pd.read_csv("data/knowledge.csv")
        return df
    except FileNotFoundError:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯åˆ¥ã®ãƒ‘ã‚¹ã‚’è©¦ã™
        try:
            df = pd.read_csv("knowledge.csv")
            return df
        except FileNotFoundError:
            st.error("knowledge.csvãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame(columns=['ç¾è±¡', 'åŸå› ', 'å¯¾ç­–', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'])

# ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—ï¼ˆäº‹å‰è¨ˆç®—ï¼‰
@st.cache_data
def compute_embeddings(df, _model):
    # ç¾è±¡ã¨åŸå› ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    texts = df['ç¾è±¡'] + " " + df['åŸå› ']
    embeddings = _model.encode(texts)
    return embeddings

# Gemini APIè¨­å®š
API_KEY = os.environ.get('GEMINI_API_KEY')
gemini_model = None

if API_KEY:
    genai.configure(api_key=API_KEY)
    try:
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        models = genai.list_models()
        model_names = [model.name for model in models]
        
        # models/gemini-1.5-proã‚’ä½¿ç”¨
        gemini_model = genai.GenerativeModel('models/gemini-1.5-pro')
    except Exception as e:
        st.sidebar.error(f"Gemini APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

# LLMå›ç­”ç”Ÿæˆ
@st.cache_data
def get_llm_response(query, context_data, _model):
    if not API_KEY or _model is None:
        return "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸãŸã‚ã€LLMæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt = f"""
    ã‚ãªãŸã¯åˆ‡å‰ŠåŠ å·¥ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®é¡ä¼¼äº‹ä¾‹ã‚’å‚è€ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å…·ä½“çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    å›ç­”ã¯ç°¡æ½”ã«ã€ç¾å ´ã§å®Ÿè·µã§ãã‚‹å†…å®¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
    
    ã€å‚è€ƒæƒ…å ±ã€‘
    {context_data}
    
    ã€è³ªå•ã€‘
    {query}
    
    ã€å›ç­”ã€‘
    """
    
    try:
        response = _model.generate_content(prompt)
        # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã®ã§ã€æŸ”è»Ÿã«å¯¾å¿œ
        if hasattr(response, 'text'):
            return response.text
        elif hasattr(response, 'parts'):
            return ''.join([part.text for part in response.parts])
        else:
            return str(response)
    except Exception as e:
        st.error(f"APIã‚¨ãƒ©ãƒ¼: {e}")
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

def main():
    st.title("åˆ‡å‰ŠåŠ å·¥ãƒŠãƒ¬ãƒƒã‚¸ AI")
    st.markdown("#### ç¾å ´ã®ç–‘å•ã‚’AIãŒè§£æ±ºã—ã¾ã™")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    if API_KEY:
        st.sidebar.write("APIæ¥ç¶š: OK")
        if gemini_model is not None:
            st.sidebar.write("ãƒ¢ãƒ‡ãƒ«: åˆ©ç”¨å¯èƒ½")
        else:
            st.sidebar.write("ãƒ¢ãƒ‡ãƒ«: åˆ©ç”¨ä¸å¯")
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
    model = load_model()
    knowledge_df = load_knowledge()
    
    # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¨ˆç®—
    if not knowledge_df.empty:
        knowledge_embeddings = compute_embeddings(knowledge_df, model)
    
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        st.sidebar.header("æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        categories = ["ã™ã¹ã¦"] + list(knowledge_df["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"].str.split(",").explode().unique())
        selected_category = st.sidebar.selectbox("ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿", categories)
        
        # ã‚ˆãæ¤œç´¢ã•ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        common_queries = ["ã³ã³ã‚ŠæŒ¯å‹•", "å·¥å…·å¯¿å‘½", "è¡¨é¢ç²—ã•", "åˆ‡ã‚Šããš"]
        st.sidebar.header("ã‚ˆãèª¿ã¹ã‚‰ã‚Œã‚‹å†…å®¹")
        for query in common_queries:
            if st.sidebar.button(query):
                st.session_state.query = query  # ã‚¯ãƒªãƒƒã‚¯ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚»ãƒƒãƒˆ
        
        # ãƒ¡ã‚¤ãƒ³æ¤œç´¢ã‚¨ãƒªã‚¢
        col1, col2 = st.columns([3, 1])
        with col1:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãŒã‚ã‚Œã°åˆ©ç”¨
            if 'query' not in st.session_state:
                st.session_state.query = ""
            
            query = st.text_input("è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šå·¥å…·ãŒã™ãã«æŠ˜ã‚Œã‚‹ã€ä»•ä¸Šã’é¢ãŒç²—ã„ãªã©ï¼‰", st.session_state.query)
        
        with col2:
            search_button = st.button("æ¤œç´¢", use_container_width=True)
        
        # æ¤œç´¢å‡¦ç†
        if search_button or ('query' in st.session_state and st.session_state.query != ""):
            if query.strip():
                # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
                query_embedding = model.encode([query])
                
                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
                similarities = cosine_similarity(query_embedding, knowledge_embeddings)[0]
                
                # ä¸Šä½3ä»¶ã®é¡ä¼¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                top_indices = np.argsort(similarities)[::-1][:3]
                
                # LLMé€£æº - ä¸Šä½ã®æ¤œç´¢çµæœã‚’LLMã¸ã®æ–‡è„ˆã¨ã—ã¦ä½¿ç”¨
                context_data = ""
                for idx in top_indices[:2]:  # ä¸Šä½2ä»¶ã‚’æ–‡è„ˆã¨ã—ã¦ä½¿ç”¨
                    if similarities[idx] > 0.3:
                        context_data += f"äº‹ä¾‹: {knowledge_df.iloc[idx]['ç¾è±¡']}\n"
                        context_data += f"åŸå› : {knowledge_df.iloc[idx]['åŸå› ']}\n"
                        context_data += f"å¯¾ç­–: {knowledge_df.iloc[idx]['å¯¾ç­–']}\n\n"
                
                # LLMã§å›ç­”ç”Ÿæˆï¼ˆæ¤œç´¢çµæœãŒååˆ†ã‚ã‚‹ã¨ãï¼‰
                if context_data and API_KEY and gemini_model is not None:
                    with st.spinner("AIå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                        llm_response = get_llm_response(query, context_data, gemini_model)
                        
                        # LLMå›ç­”ã‚’è¡¨ç¤º
                        st.markdown("## AIã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                        st.markdown(llm_response)
                        st.caption("â€»ã“ã®å›ç­”ã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚æœ€çµ‚åˆ¤æ–­ã¯å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚")
                
                # æ¤œç´¢çµæœã‚’ã‚«ãƒ¼ãƒ‰UIã§è¡¨ç¤º
                st.subheader("æ¤œç´¢çµæœ")
                found_results = False
                for i, idx in enumerate(top_indices):
                    if similarities[idx] > 0.3:  # é¡ä¼¼åº¦ã—ãã„å€¤
                        found_results = True
                        with st.expander(f"{knowledge_df.iloc[idx]['ç¾è±¡']} (é¡ä¼¼åº¦: {similarities[idx]:.2f})", expanded=True if i==0 else False):
                            cols = st.columns(3)
                            with cols[0]:
                                st.markdown("### ç¾è±¡")
                                st.write(knowledge_df.iloc[idx]['ç¾è±¡'])
                            with cols[1]:
                                st.markdown("### åŸå› ")
                                st.write(knowledge_df.iloc[idx]['åŸå› '])
                            with cols[2]:
                                st.markdown("### å¯¾ç­–")
                                st.write(knowledge_df.iloc[idx]['å¯¾ç­–'])
                            
                            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³
                            feedback_cols = st.columns([1,1,4])
                            with feedback_cols[0]:
                                st.button("ğŸ‘ å½¹ç«‹ã£ãŸ", key=f"useful_{idx}")
                            with feedback_cols[1]:
                                st.button("ğŸ‘ å½¹ç«‹ãŸãªã‹ã£ãŸ", key=f"not_useful_{idx}")
                
                if not found_results:
                    st.warning("ååˆ†ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.info("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        st.error("ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()